大家好，我们继续共享单车数量预测任务的实战。



在我的公众号`Coder梁`后台回复`ai`，获取无魔法无限使用GPT4.0的方式。


## 拆分数据



在上一篇文章当中，我们完整实现了训练一个神经网络模型的过程，并且得到了一个还不错的模型。随着训练过程中模型地迭代，模型预测的结果和真实值之间的误差也随之越来越接近0。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240221000940124.png)



不知道大家看到这个结果有没有更兴奋，先别着急兴奋，这个结果是有问题的。最大的问题是我们没有区分训练集和测试集，导致模型测试和训练在同样一份数据上进行，这显然是有问题的。



就好像一个学生学习和考试的时候做同一套试题，这肯定无法测试出学生的真实水平，会导致得到的分数偏高。放在模型上也是一样的，模型在测试集上也会有表现偏高的问题。



所以要解决这个问题，我们必须要拆分数据，把测试数据和训练数据区分开，从而能够得到相对逼真的模型性能。



最终我们需要三份数据，分别是训练集、验证集和测试集。借用一下真实考试的场景，很好理解。训练集就是学生学习时做的习题和作业，用来帮助模型训练的。验证集就是平时的小考，用来验证检验模型的学习情况，最终的测试集就是最终考试，用来评估模型的训练效果。



模型在训练的过程当中，需要经过多轮迭代，根据梯度下降的原理我们知道，当模型逼近拟合时，继续训练迭代会导致模型陷入震荡。验证集就是在此时发挥作用的，它用来验证模型的训练过程。每次我们都会将在验证集上表现最好的模型参数保存下来，通过这种方式来人为降低参数波动对模型效果的影响。



拆分数据本身很简单，因为`sklearn`中已经有了现成的工具库了，我们只需要拿来用即可。



```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=23)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=23)
```



我们在使用`train_test_split`的时候传入了四个参数，分别是特征集、标签，`test_size`和`random_state`。`test_size`是我们要划分的测试集的大小，可以是一个`[0, 1]`之间的浮点数表示样本的百分比，也可以是一个整数，表示具体的条数。最后的`random_state`可以省略，用来传入随机数种子。



划分好了验证集和测试集之后，剩下的代码和之前几乎一样，只不过我们绘制loss图的时候，用的是验证集的数据，而非全量数据。



```python
# 将数据转化成tensor
X_tensor = torch.tensor(X_train).float()
y_tensor = torch.tensor(y_train.to_numpy()).float()

dataset_train = TensorDataset(X_tensor, y_tensor)
data_iter = DataLoader(dataset=dataset_train, batch_size=23, shuffle=True)

X_val_tensor = torch.tensor(X_val).float()
y_val_tensor = torch.tensor(y_val.to_numpy()).float()

X_test_tensor = torch.tensor(X_test).float()
y_test_tensor = torch.tensor(y_test.to_numpy()).float()

loss = nn.MSELoss()
optim = torch.optim.SGD(net.parameters(), lr=0.0003)

num_epochs = 3
best_loss = float('inf')

losses = []
for epoch in range(num_epochs):
    for dtx, dty in data_iter:
        l = loss(net(dtx).squeeze() ,dty)
        optim.zero_grad()
        l.backward()
        optim.step()
        with torch.no_grad():
            l = loss(net(X_val_tensor).squeeze(), y_val_tensor).detach().numpy()
            if l < best_loss:
                best_loss = l
                torch.save(net.state_dict(), '../resource/bike/v1.pth')
            losses.append(l)
```



这里我们加上了根据每一轮迭代时的`loss`判断是否保存模型参数的逻辑。



并且由于我们拆分出了测试集，我们可以直接查看模型在测试集上的表现了。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240226221758009.png)



考虑到我们除了归一化之外没有对特征做任何处理，能有这样的结果已经是很不错了。



## 可视化



这里我们只看到了一个浮点数的误差，显得不够直观，为了更清晰地看到我们的模型到底预测有多精确，我们可以人工选出一批数据来进行可视化。



由于我们刚才训练的时候的测试集和验证集都是随机抽取的，这会使得可视化的时候不够直观。



为了更加直观，我们对验证集和测试集的构造做一点手脚，人为选出最末尾的一部分数据作为验证集和测试集：



```python
X_train, X_test, y_train, y_test = X[:-21*24], X[-21*24:], y[:-21*24], y[-21*24:]
X_train, X_val, y_train, y_val = X_train[:-21*24], X_train[-21*24:], y_train[:-21*24], y_train[-21*24:]
```



模型训练部分的代码不变，在模型训练完成之后，我们做一点可视化的工作，将模型预测值和真实值都在图上显式出来。



```python
testset = pd.DataFrame(df.iloc[:, ][-21*24:], columns=df.columns)
targets = testset['cnt']
targets = targets.values.reshape([len(targets), 1])
targets = targets.astype('float')
# 测试集做归一化，直接调用transform即可，而不是fit_transform
x = torch.FloatTensor(scaler.transform(testset.iloc[:, 2:]))
y = torch.FloatTensor(targets)
# 模型预测结果
pred = net(x).squeeze().detach().numpy()

import numpy as np

fig, ax = plt.subplots(figsize = (10, 7))

ax.plot(pred, label='predict')
ax.plot(targets, label='Data')
ax.legend()

ax.set_xlabel('Date-time')
ax.set_ylabel('Counts')

dates = pd.to_datetime(testset['dteday'])
dates = dates.apply(lambda x: x.strftime('%b %d'))
ax.set_xticks(np.arange(len(dates))[12::24])
_ = ax.set_xticklabels(dates[12::24], rotation=45)
```

![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240227200149896.png)

这两条线几乎重合……



说明模型的拟合效果已经非常好了，我们在看一下模型在测试集上的损失值：



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240227200320037.png)



## 改进空间



虽然模型的效果已经很好了，但不代表我们已经做到了极致，实际上我们在特征层面做的很少，只有一个最基础的归一化。



下面介绍两种算法工程师日常中最常使用的两种处理特征的方法：onehot和embedding。



### onehot



`onehot`这个单词非常形象，翻译过来就是只有一个热，这是什么意思呢？



它针对的是类别型特征，比如这次实验中的季度、当前时间、月份、周几等特征。这些特征的特点是它们表示的是一个类别，而非数字。比如我们用1到7来表示周一到周日，这表面上固然可行，但是内里的逻辑是有问题的。因为1到7的数字是有大小和倍数关系的，这个关系会影响到模型的表达，而周一到周日在逻辑上是不存在大小和倍数关系的，它们表示的不同的概念。



因此我们直接用一个数字来代表它们的做法是不妥当的，会影响模型的效果。



`onehot`就是一种解决的策略，它通过拓展维度的方法来保证特征之间在逻辑上的公平表达。比如原本周几是一个特征，`onehot`会将它拓展成7个，只有特定的位置为1，其余位置均为0。比如周一就是`[1, 0, 0, 0, 0, 0]`，周日就是`[0, 0, 0, 0, 0, 0, 1]`。



这样在模型当中，获取特征的时候，周一到周日的取值范围均相同，由于只有一位为1，其余均为0，每次只有一位能够起作用，彼此之间也不存在数学上的大小和倍数关系。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240227200447220.png)



### embedding



`onehot`虽然巧妙，但也有缺陷，当一个特征类别很多的时候，会导致大量的浪费。



比如淘宝的商品类目，可能有上千万，如果我们用`onehot`的方法来处理它的话，会导致拓展出的特征数量非常巨大。因此会带来许多问题，比如数据稀疏的问题，以及模型训练和部署时的性能问题等。



所以在实际的工作当中，`onehot`已经很少使用了。



取而代之的做法是embedding，embedding本身英文的意思是嵌入，在机器学习领域当中指的是嵌入向量。和`onehot`不同的是，我们不会将特征拓展，而是使用一个高维向量来表示不同的类别。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240227201415800.png)



我们假设embedding的向量长度是4，表达的特征是周几。



周一对应的向量可能是`[0.3, 0.9, -0.6, 0.7]`，周日对应的向量可能是`[-1.0, 0.5, 0.1, -0.8]`。我们不再是用0和1来区分类别，而是使用向量。



这样的做法好处很多，比如向量的表达能力比0和1的单一维度强很多，向量中包含的信息与向量的长度以几何级增长。其次，由于向量的表达能力很强， 对于数量众多的类别特征支持很好。比如某个特征种类有上千万之多，如果使用`onehot`，那么需要上千万维的特征才行，这上千万维度当中只有一维是1，其余全是0，会带来巨大的浪费。而使用向量表达的话，可能只需要16维或者32维就够了。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240227202337811.png)



这里由于我们的模型效果已经非常出色，所以就不多此一举添加这两个特征了。



大家感兴趣的话，可以自己动手试一试。pytorch和sklearn当中对于`onehot`和embedding都有很好的支持。有ChatGPT帮助，相信大家都可以手到擒来。



最后，宣传一下我的星球。



除了Ai什么都有，个人学习成长、理财投资、量化交易心得，持续更新中



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/%E6%98%9F%E7%90%83%E4%BC%98%E6%83%A0%E5%88%B8%20(6).jpeg)

