这一章节主要是关于前期的准备部分。



首先，我们先跳过机器学习的部分。



这并不是说机器学习不重要，实际上机器学习和深度学习并不是两个割裂的概念，而是包含关系。深度学习只不过特指使用深度神经网络模型的机器学习算法，只不过由于神经网络的性能过于优异，导致如今大部分场景当中，已经很难见到纯粹的机器学习模型了。



对于大部分从业者来说，一般只有在准备面试或者面临特定需求的时候，才会需要用到机器学习的模型。并且一些机器学习的模型学习起来难度不低，所以我们先跳过这个部分，直接从深度学习开始，先理解机器学习的思想，等有了需求之后再去补上这块内容。



做好跳过了机器学习大量内容的心理建设之后，我们正式开始准备工作。



## 配置环境



首先是最基础的Python环境，这个一般计算机里都有。没有的话问题也不大，我们直接下载安装anaconda即可。



anaconda是一个集成式的Python数据科学和机器学习平台，我们直接安装它就搞定了Python环境。并且它还能帮我们管理Python的虚拟环境以及包环境，从我个人体验下来，直接安装conda要比去折腾pip对新手来说更加友好。



安装的方法以及问题解决我们可以直接通过询问ChatGPT完成。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240118235359018.png)



## 安装pytorch



搞定了conda之后，我们来安装Python中的深度学习框架。



Python平台有名的深度学习框架不少，常见的有TensorFlow、Pytorch、百度的paddle等。其中TensorFlow和Pytorch我个人都比较深度的使用过，对于学习者而言，无脑推荐Pytorch。毕竟我们做模型的目的是学习，而不是为了线上部署，TensorFlow易于部署、线上性能优异等特性并用不上。而它的缺点，api混乱，版本之间的兼容性较差等问题对于新手的影响是致命的。



所以无脑选Pytorch即可，这些框架之间各有优劣，目的都是为了实现模型，没有选错一说。所以不必纠结。



同样Pytorch的安装方法我们也可以通过询问ChatGPT搞定。

![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240118235629738.png)



## 显卡支持



可能你或许听说过，深度学习的训练需要用到显卡。



然而并不是什么显卡都能用来训练模型的，其中对于深度学习支持最好的是英伟达，几乎主流的深度学习框架都支持CUDA使用显卡对模型训练进行加速。除了英伟达之外，AMD和Intel的显卡虽然可以使用OpenCL，但它的兼容性远远不如CUDA。我没有用过AMD的显卡，没有体验过，有这方面需求的小伙伴也可以询问ChatGPT。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240119000858200.png)



另外，苹果家的M1、M2、M3芯片也可以使用mps在Pytorch上进行加速。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240119001528687.png)



这块内容比较新，直接问ChatGPT可能没有结果，大家可以去搜索一下。关键词：Metal Pytorch。



千万不要小看显卡，有显卡和没显卡，显卡性能强和弱差距非常大……



我最近刚好在训练模型， 给大家提供一个参考。我用了一个6层的transformer encoder模型，在4090上的速度是M3芯片的Mac使用mps加速的7倍。而mps加速之后的速度又是CPU训练的4-5倍，也就是说4090的训练速度是CPU的30倍左右。



这个差距是非常恐怖的，4090跑30分钟抵得上CPU训练十几个小时。所以在开始学习之前，大家最好能花点时间查看一下自己手边的设备，有没有适合加速训练的显卡。



如果实在没有也没关系，CPU训练也是可以的，无非慢一些罢了。


欢迎加入我的星球~


![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/%E6%98%9F%E7%90%83%E4%BC%98%E6%83%A0%E5%88%B8%20(6).jpeg)