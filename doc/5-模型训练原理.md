今天这篇文章我们来聊聊机器学习的原理。



我之前写过一整个机器学习的专栏，但我现在回想起来，可能依旧不是一个很新手友好的读物，太过讲究理论而忽略读者的接受程度。实际上这也是我觉得目前市面上大多数教程的问题，太过追求正确和高大上了。我现在反倒觉得也许简单易懂更重要，甚至稍稍牺牲一些正确性都无可厚非。



所以今天这篇文章咱们会尽量简单点，少讲一些理论。



## 什么是机器学习



在很多人眼里，会把机器学习和神经网络、人工智能、算法等概念混为一谈。这个概念真的挺酷的，字面意思简单易懂，却又给人十足高大上的感觉。



如果你想要知道详细的科学的解释，你可以去问ChatGPT。它不但能给出学术解释，还更进一步总结了机器学习的类别。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240125213917382.png)



我个人对机器学习的理解要简单一些，就三个字“找函数”。



本质上，是我们面临一个具有通用性的未知解的问题，我们人工判断可能存在某种高维的信息和规律，然而又无法精准地使用逻辑或数学去表达。所以设计了一系列的算法，使得我们可以通过大量数据去矫正模型的参数，从而获得一个比较良好的次优解。



我们清楚地知道存在这样的一个函数`f`，能够对我们特定形式的输入`x`，给出很好的结果`f(x)`。我们虽然能确定这样的函数存在，但却无法给出详细的描述和定义。就好比我们每个人都有人脸识别的功能，但我们却没办法说出我们是怎么识别的。就更勿论通过代码去实现类似的功能了。



那这个时候该怎么办呢？



我们虽然没办法明确问题背后的数学模型究竟是什么，但既然我们确定它存在，我们就可以一点点逼近它。我们通过逻辑推演构想出一个可能的模型，然后通过实际的数据去验证效果。如果效果很好，说明我们的构想是有意义的，反之则说明构想还不够成功还需要继续优化和改进。本质上这是一个寻找一个个次优解逐渐逼近真实解的过程。



算法研究在做的工作，其实就是通过实验和反复推演寻找更好的解法，科学家们一次次站在前人的肩膀上向更高处探索。



最终，当我们终于在某个问题上获得了一个足够好的解法时，我们就可以认为该问题已经被解决了。比如人脸识别问题，现在算法的识别准确率已经非常高了，甚至要超越了人类。但我们仍然没有搞清人类是怎么识别人脸的，背后的逻辑又是什么，我们只不过在机器上找到了一个代替的方法。



## 怎么学习



这种我们通过分析构想出来通过代码实现来解决实际问题的东西叫做模型（model），你可以简单理解成一种算法，只不过通常算法的运行逻辑和输入输出都是明确的，而模型则相对模糊一些。特别是一些比较复杂的模型，内部的逻辑是一个黑盒。



模型是很容易开发的，但模型内部的参数却是很难确定的。



以最简单的线性回归模型为例，线性回归模型本质上是一个加权求和的模型。模型会为每一个输入的特征赋予一个对应的权重，进行加权求和之后输出。无论是逻辑上还是实现上，它都非常简单，但问题是，我们怎么确定这些特征的权重呢？尤其在特征数量多的情况下，更是复杂。



机器学习开创性地提出了通过数据训练模型的方法，所谓地训练，即让模型根据大量数据通过真实值和模型预测值之间的偏差自行调整内部的参数，从而更好地拟合数据的过程。



## 训练过程



光看文字描述，对于初学者来说可能还是比较玄，不太能get到，没关系，我们来看一个实际的例子。



假设我们的模型是$h_\theta$，这里的$\theta$就是模型中的参数。模型的预测值是$\hat{y}=h_\theta(x)$，$x$是样本，也就是我们搜集到的特征数据，样本的真实值是$y$，也就是我们希望模型预测的结果。



我们先忽略模型内部的逻辑，不同的模型内部实现不同。我们先不管，先从宏观上理解模型训练的过程。后面再具体学习模型编写的时候，再来补上这个环节。



宏观上来说，我们希望我们模型的预测值能和实际观测到的真实值尽量接近。我们每次迭代时对模型内部的参数值进行调整，就是以这个观测值和模型的预测值之间的差异做驱动的。首先，我们需要先定义一个函数来描述这两者之间的差异，也就是将差异转化成数学表达。



这个函数叫做损失函数（loss function），很直观，现实永远是对的，模型的差异都是一种损失。损失越大说明模型的表现越差，越小说明表现越好。我们要做的就是优化模型的参数，使得损失函数的结果尽量小。不同的模型和不同的问题当中，通常会使用不同的损失函数，但不管选什么，它底层的逻辑都是一致的，就是预测值和真实值之间的差异体现。



我们以均方差这个损失函数为例，它一般被用在回归问题当中。回归问题就是预测值问题，模型会给出一个值作为预测结果。而分类问题当中，模型给出的是一个预测类别或者是类别的概率。



均方差的公式为：



$$loss = \frac 1 2 \sum_{i=1}^n(y_i - \hat{y}_i)^2$$



也就是预测值和真实值之间的平方和，因为求平方之后可以保证这个差值一定是个正数。



那有了损失函数之后，又该怎么训练模型呢？



在有了损失函数之后，这个问题可以转化成数学上的最值问题了。我们有了函数方程，需要寻找函数取最值时对应的参数。这当然是可以的，在线性回归当中，我们的确可以通过数学推导公式，直接来求参数的解。



但一般情况下我们不这么做，一则是直接计算的复杂度往往很大，并且条件很苛刻，并不是适用于所有数据。二则，仅仅是线性回归一类的简单模型能够通过数学推导，在神经网络当中，往往模型内部非常复杂，直接通过数学求解几乎是不可能的。



直接求解不可能，所以我们退而求其次，而采用迭代法。即每一次迭代都会把参数向损失函数值减小的方向优化一点点，经过多次反复迭代之后，直到损失函数不能再减小时停止，这时候我们就会认为模型已经收敛了。



迭代时，我们会求损失函数关于参数$\theta$的偏导，进而求出损失函数减小对应的向量，参数沿着这个向量的方向迭代就可以使得损失函数值减小，这个向量我们称为*梯度*。这种多次沿着梯度下降方向迭代使得损失函数值减小的算法称为*梯度下降算法*。



我们可以参考下图获得一个比较直观的认知：



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/0063.png)



在深度学习当中，框架替我们封装好了求偏导以及参数更新的内容。



所以我们不需要操心这些，我们只需要编写模型本身和数据链路的部分，框架会自动替我们完成求偏导和反向传播的过程。虽然但是，对于从业者来说，这部分理论知识属于基础中的基础，是必须了解和掌握的。



当然和梯度下降以及模型训练相关还有很多知识没有涉及，都放在一篇文章里也不太合适。本文只保留了最核心的内容，帮助大家从宏观上了解模型训练的过程和基本原理，其中的细节等后续遇到的时候再详细阐述。



最后，欢迎加入我的星球~



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/%E6%98%9F%E7%90%83%E4%BC%98%E6%83%A0%E5%88%B8%20(6).jpeg)