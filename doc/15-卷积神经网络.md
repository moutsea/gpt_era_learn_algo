大家好，今天来聊聊卷积神经网络。



公众号`Coder梁`后台回复`ai`，无魔法无限使用GPT4，我个人用了好几个月了，真诚推荐。



在上一篇文章当中，我们一起做了一个经典的手写数字多分类模型，训练了一个模型来识别手写的数字究竟是几。在文章的最后，模型获得了95%的准确率。



不得不说，这个准确率已经非常好了，毕竟人类在这个问题上的表现是98%，也就高三个百分点而已。在绝大多数要求不是那么严格的场景中，已经达到实用的标准了。



如果我们还想要变得更好，拿到更好的效果，应该从何处下手呢？



## 卷积神经网络



要找到前进的方向，就需要先找到当下的不足。



在之前的做法当中，我们把一个`28 x 28`的图片展开成了`1 x 784`的一维向量。表面上看着好像没什么问题，挺符合直觉，但实际上还是能想到一些不足。



比如，有些数字在手写体中是比较近似的，比如1和7，再比如8和0。如果展开成一维的话，会导致在绝大多数维度上这两个数字的样本非常近似。



再比如，样本当中也存在偏差，举个直观的例子，由于每个人书写习惯不同，不同人写出的数字的风格差异是很大的。比如位置和大小的差异，有些人习惯将数字写得很大，有些人则习惯写得小，还有些人写出来的数字偏左，自然也有些人靠右。



这些因素都会导致在展开成一维向量之后，增大模型的识别难度。



我们可以回想一下人类是怎么看东西的，我们看到一张图片的时候，看到的是这张图的整体，我们得到的直接是这张图抽象到极致之后的结果。



这个抽象的整体又是基于一些局部的特征来的，例如人物的鼻子、眼睛等。而局部的特征又是由更细粒度的线条、阴影、颜色块等元素构成的。最后，再往下细分才得到一个一个的像素点。大家可以对照一下下图试着加深一下理解。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/d447a-2019-06-19-renlei-shijue2.jpg)



正因为人类看东西的时候，看的是物体的这些抽象特征，所以我们才完全不会受到图片大小、位置、角度等因素的影响。



如果我们也赋予模型同样的能力，那么是不是模型也能像人类一样识别准确呢？



答案是可以的，至少在手写数字这个问题上，已经得到了证实。通过合理的模型结构， 算法可以达到超过99%的识别准确率，这已经超过人类的表现了。



这里所说的合理的模型结构就是卷积神经网络。



#### 卷积层



首先我们要理解卷积神经网络的作用，它需要用到一个特殊的矩阵，叫做卷积核，也被称作滤波器。



卷积核的作用就是用来从图片当中提取出特征，怎么提取呢，很简单，和图片的一部分做矩阵乘法。卷积核的尺寸通常比较小，比如`1 x 1, 3 x 3, 5 x 5`等，而图片的尺寸通常会大得多。所以在做卷积操作的时候，我们会把卷积核均匀地在原始图片上移动不停地做卷积操作，这样执行若干次之后，我们就得到了一张“新图”，这就是卷积核提取出来的特征图。



如果不理解的话，可以参考一下下图。



![](https://easyai.tech/wp-content/uploads/2022/08/f144f-2019-06-19-juanji.gif)



执行完一次卷积操作之后，原始图片的尺寸会发生一些变化。



我们假设图片的原始长度是$W$，宽度是$H$，卷积核的尺寸是$F$，每次移动的步长是$S$，padding的长度是$P$。那么进行过一次卷积操作之后，新的图片的尺寸是：


$$
\begin{align}
W_{out} = \frac {W - F+2P}S + 1 \\
H_{out} = \frac {H - F+2P}S + 1
\end{align}
$$
我们先忽略padding，假设卷积核的尺寸是3，每次移动的步长是1的话，那么每次卷积操作执行结束之后，得到新图的尺寸会比原始的小2。



在一些情况下，这会让图片的尺寸变来变去，导致我们实现模型的过程比较繁琐。因为在一些较大型的模型当中，动辄会用到十几层甚至更多的卷积层的叠加。



因此如果我们不想产生这样的变化，我们可以在原图的外侧加上padding，也就是填充，比如在$F=3, S=1$的情况下，我们可以填充一层0，这样就可以让卷积之后的图片和原始图片的尺寸一样。



在实际操作当中，我们可以使用多个卷积网络来提取不同的特征，从而更好地帮助模型识别图片信息。



#### 池化层



但是只有卷积层是不够的，这会带来一个问题，就是模型参数过大的问题。



在本题当中图片的范围比较小，这个问题不是很明显，在一些涉及高清图片的问题中，由于图片的像素很高会导致模型的参数因此变得非常巨大。比如4K分辨率下，图片的尺寸将会达到3840 x 2160，总共超过八百万像素。并且图片通常会有多个信道(channel)，比如常见的红绿蓝。



再叠加多个卷积层，每层又会有多个卷积核，这会使得模型的参数膨胀到一个恐怖的地步。



因此就必须引入特征提取机制了，最常见的方式就是池化层，英文叫做pooling。



所谓池化其实就是采样，就是从一个区域中选出最大值或者是均值来。如果是选最大值就是最大值池化(max-pooling)，如果是选均值就是均值池化(avg-pooling)，参考下图：



![](https://easyai.tech/wp-content/uploads/2022/08/3fd53-2019-06-19-chihua.gif)

池化层也会有一个范围在图片中移动来计算最大值或者是均值，经过池化层的采样之后，可以将图片的尺寸大大缩小。比如最常见的`2 x 2`的池化层，可以将原图的尺寸缩小一半，长宽都缩小一半，落实到具体的参数量上就是缩小到原来的四分之一。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240411212150360.png)



通常在模型实现中会将卷积层与池化层交替排列。



### dropout



最后还有dropout值得一提，dropout没有一个合适的翻译，它是一种特殊的激活函数。它的原理是在训练的时候随机屏蔽掉一定比例的神经元，从而迫使模型训练时不过度依赖某一个特定的特征，从而实现避免过拟合的目的。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240411212657902.png)



dropout更多的是一种思想，而非一种技术，我们只需要知道相关原理会使用即可。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240411213543736.png)



深度学习框架层面已经替我们做好了相关的处理。



最后就是模型的实现了，在我们了解了卷积和池化的原理之后，已经没什么难度了，顶多一些api的细节不清楚，问一下GPT即可。



这是卷积层的参数：



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240411215926696.png)



这里解释一下输入通道，也就是channel，一开始是原始图片的channel。一般的图片channel是3，也就是黄绿蓝三原色。在本题当中只有一个维度，所以是1。`out_channel`表示卷积层的卷积核的数量，每个卷积核都会卷积出一张新的特征图来，因此它的`out_channels`就是下一层卷积的`in_channels`。



通常，越往后模型提取出的特征越抽象，图片的尺寸越小，提取到的特征越多。到最后，完全展平，只保留特征信息。所以通常越往后channel的数量越大。



一般情况下，在有多层卷积层的情况下，我们是很难知道channel的合理设置，所以设置出来的数量都是有冗余的。这也是我们要使用dropout的原因，这也使得dropout几乎成了卷积神经网络的标配。



```python
class CronvNet(nn.Module):
    def __init__(self, input_dim=28, hidden_dim=128, classes=10):
        super(CronvNet, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.5)

        self.fc1 = nn.Linear(input_dim // 4 * input_dim // 4 * 16, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)

        x = F.relu(self.conv2(x))
        x = self.pool(x)

        # 向量展平
        x = torch.flatten(self.dropout(x), 1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
```



这里有几处细节，大家在实现的时候，尤其是新入门的同学需要特别注意一下：



1. 计算好每次卷积核池化之后图片大小的变化，这是重中之重
2. 池化层不涉及参数，只需要定义一次。之后每次卷积都可以使用同一个池化层来完成池化操作
3. 在最后进行`log_softmax`操作之前，不需要再经过激活函数。因为`log_softmax`本身就可以看成是一个激活函数，并且它用来直接输出来计算每个类别的概率，不能再经过激活函数，否则会带来巨大偏差



在使用卷积神经网络之后，我们可以发现模型的准确率有了进一步的提高，超过了98.5%。相比之前展开的做法，又提升了三个多点，这在机器学习领域当中可以说是飞跃一般的提升了。



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240411220350901.png)



最后，宣传一下我的星球。



除了Ai什么都有，目前在更新《穷爸爸与富爸爸》读书笔记，欢迎加入讨论



![](https://moutsea-blog.oss-cn-hangzhou.aliyuncs.com/image-20240404143631289.png)